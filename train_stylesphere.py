import json
import os
import math
import random
from llama_cpp import Llama
from tqdm import tqdm
import yaml
from typing import List, Dict, Any

def load_config(config_path="train_stylesphere.yaml"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

# åŠ è½½StyleSphereé…ç½®
CONFIG = load_config()

def load_training_data(file_path):
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

def format_prompt(instruction, input_text=""):
    """StyleSphereçš„æç¤ºæ¨¡æ¿"""
    if input_text:
        return f"[INST] {instruction}\n{input_text} [/INST]"
    return f"[INST] {instruction} [/INST]"

def get_learning_rate(current_step, total_steps, config):
    """å®ç°å¸¦warmupçš„ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦"""
    warmup_steps = config['warmup_steps']
    max_lr = config['learning_rate']
    min_lr = max_lr * 0.1  # æœ€ä½å­¦ä¹ ç‡ä¸ºæœ€å¤§å­¦ä¹ ç‡çš„10%

    if current_step < warmup_steps:
        # çº¿æ€§é¢„çƒ­
        return max_lr * (current_step / warmup_steps)
    else:
        # ä½™å¼¦è¡°å‡
        progress = (current_step - warmup_steps) / (total_steps - warmup_steps)
        return min_lr + 0.5 * (max_lr - min_lr) * (1 + math.cos(math.pi * progress))

def calculate_loss(output_text, target_text):
    """è®¡ç®—ç”Ÿæˆæ–‡æœ¬ä¸ç›®æ ‡æ–‡æœ¬ä¹‹é—´çš„æŸå¤±"""
    if not output_text:
        return 1.0
    
    # è®¡ç®—æœ€é•¿å…¬å…±å­åºåˆ—
    def lcs_length(text1, text2):
        m, n = len(text1), len(text2)
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if text1[i-1] == text2[j-1]:
                    dp[i][j] = dp[i-1][j-1] + 1
                else:
                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])
        return dp[m][n]
    
    # ç»“åˆå­—ç¬¦åŒ¹é…åº¦å’Œæœ€é•¿å…¬å…±å­åºåˆ—
    char_match = sum(1 for a, b in zip(output_text, target_text) if a == b)
    lcs = lcs_length(output_text, target_text)
    total_length = max(len(output_text), len(target_text))
    
    # ç»¼åˆè€ƒè™‘å¤šä¸ªæŒ‡æ ‡
    char_match_ratio = char_match / total_length if total_length > 0 else 0
    lcs_ratio = lcs / total_length if total_length > 0 else 0
    length_penalty = abs(len(output_text) - len(target_text)) / total_length
    
    # è®¡ç®—åŠ æƒloss
    loss = 1.0 - (0.4 * char_match_ratio + 0.4 * lcs_ratio - 0.2 * length_penalty)
    return min(max(loss, 0.0), 1.0)

def apply_data_augmentation(text):
    """StyleSphereä¸“ç”¨çš„æ•°æ®å¢å¼ºæ–¹æ³•"""
    # æ·»åŠ æ—¶å°šç›¸å…³çš„è¡¨æƒ…ç¬¦å·
    emojis = ['ğŸ’„', 'ğŸ‘—', 'ğŸ‘ ', 'ğŸ‘œ', 'ğŸ’…', 'ğŸ‘š', 'ğŸ‘’', 'ğŸ’ƒ', 'âœ¨', 'â¤ï¸']
    if random.random() < 0.3:
        text = text + ' ' + random.choice(emojis)
    
    # æ·»åŠ æ—¶å°šç›¸å…³çš„ç§°è°“
    nicknames = ['äº²çˆ±çš„', 'å®è´', 'ç¾å¥³', 'å§å¦¹']
    if random.random() < 0.2 and not any(name in text for name in nicknames):
        text = random.choice(nicknames) + 'ï½' + text
    
    return text

def initialize_model(config):
    """åˆå§‹åŒ–æ¨¡å‹"""
    model_params = config.get('model_params', {})
    return Llama(
        model_path=config['model_name_or_path'],
        n_ctx=model_params.get('n_ctx', config.get('max_source_length', 2048)),
        n_batch=config.get('per_device_train_batch_size', 2),
        n_threads=6,
        n_gpu_layers=model_params.get('n_gpu_layers', 0),  # ä» model_params è¯»å– n_gpu_layers
        verbose=True,
        embedding=True,
        seed=42
    )

def evaluate_model(llm, eval_data):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    total_loss = 0
    for item in eval_data:
        prompt = format_prompt(item["instruction"], item["input"])
        target = item["output"]
        
        try:
            completion = llm(
                prompt,
                max_tokens=len(target) + 50,
                temperature=0.1,
                stream=False
            )
            
            if isinstance(completion, dict) and 'choices' in completion:
                output_text = completion['choices'][0]['text']
                loss = calculate_loss(output_text, target)
                total_loss += loss
            else:
                total_loss += 1.0
                
        except Exception as e:
            print(f"è¯„ä¼°æ—¶å‡ºé”™: {str(e)}")
            total_loss += 1.0
            
    return total_loss / len(eval_data)

def train_stylesphere():
    """StyleSphereä¸“ç”¨è®­ç»ƒæµç¨‹"""
    config = CONFIG
    
    # åˆ›å»ºè¾“å‡ºå’Œæ—¥å¿—ç›®å½•
    os.makedirs(config['output_dir'], exist_ok=True)
    os.makedirs(config['logging_dir'], exist_ok=True)
    log_file_path = os.path.join(config['logging_dir'], 'training_log.jsonl')
    
    # åˆå§‹åŒ–æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    llm = initialize_model(config)
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    print("æ­£åœ¨åŠ è½½è®­ç»ƒæ•°æ®...")
    training_data = load_training_data(config['train_data'])
    validation_data = load_training_data(config['val_data'])
    
    # è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°
    total_steps = config['max_steps']
    current_step = 0
    accumulated_loss = 0
    best_eval_loss = float('inf')
    
    # å¼€å§‹è®­ç»ƒ
    print("å¼€å§‹StyleSphereè®­ç»ƒ...")
    num_epochs = total_steps // len(training_data) + 1
    
    with open(log_file_path, 'w', encoding='utf-8') as log_file:
        for epoch in range(num_epochs):
            total_loss = 0
            progress_bar = tqdm(training_data, desc=f"Epoch {epoch+1}")
            
            for item in progress_bar:
                current_step += 1
                if current_step > total_steps:
                    break
                    
                current_lr = get_learning_rate(current_step, total_steps, config)
                
                # å‡†å¤‡è¾“å…¥ï¼Œåº”ç”¨StyleSphereçš„æ•°æ®å¢å¼º
                prompt = format_prompt(item["instruction"], item["input"])
                target = apply_data_augmentation(item["output"])
                training_text = prompt + " " + target
                
                try:
                    # ä½¿ç”¨llama.cppè¿›è¡Œè®­ç»ƒ
                    completion = llm(
                        training_text,
                        max_tokens=0,
                        temperature=0,
                        echo=True,
                        stream=False
                    )
                    
                    # æå–è¾“å‡ºå¹¶è®¡ç®—loss
                    if isinstance(completion, dict) and 'choices' in completion:
                        output_text = completion['choices'][0]['text']
                        loss = calculate_loss(output_text, target)
                    else:
                        output_text = ''
                        loss = 1.0
                    
                    # æ¢¯åº¦ç´¯ç§¯
                    accumulated_loss += loss / config['gradient_accumulation_steps']
                    
                    if current_step % config['gradient_accumulation_steps'] == 0:
                        total_loss += accumulated_loss
                        accumulated_loss = 0
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.set_postfix({
                        'loss': f'{loss:.4f}',
                        'lr': f'{current_lr:.6f}'
                    })
                    
                    # è®°å½•æ—¥å¿—
                    log_entry = {
                        'step': current_step,
                        'loss': loss,
                        'lr': current_lr
                    }
                    
                    # å®šæœŸè¯„ä¼°å’Œä¿å­˜
                    if current_step % config['logging_steps'] == 0:
                        eval_loss = evaluate_model(llm, validation_data[:10])
                        log_entry['eval_loss'] = eval_loss
                        print(f"\næ­¥éª¤ {current_step} è¯„ä¼°æŸå¤±: {eval_loss:.4f}")
                        
                        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œä¿å­˜æ£€æŸ¥ç‚¹
                        if eval_loss < best_eval_loss:
                            best_eval_loss = eval_loss
                            checkpoint_dir = os.path.join(config['output_dir'], f'best_checkpoint')
                            os.makedirs(checkpoint_dir, exist_ok=True)
                            print(f"å‘ç°æ›´å¥½çš„æ¨¡å‹ï¼ä¿å­˜æ£€æŸ¥ç‚¹åˆ°ï¼š{checkpoint_dir}")
                            
                        # æµ‹è¯•ç”Ÿæˆæ•ˆæœ
                        test_prompt = "è¯·ä¸ºä¸€ä¸ªèº«é«˜165cmçš„å¥³ç”Ÿæ¨èå¤å­£ç©¿æ­"
                        print("\næµ‹è¯•ç”Ÿæˆï¼š")
                        test_result = llm(
                            format_prompt(test_prompt),
                            max_tokens=200,
                            temperature=0.7,
                            stream=False
                        )
                        
                        if isinstance(test_result, dict) and 'choices' in test_result:
                            generated_text = test_result['choices'][0]['text']
                            print(f"æç¤ºï¼š{test_prompt}")
                            print(f"ç”Ÿæˆï¼š{generated_text}\n")
                    
                    log_file.write(json.dumps(log_entry) + '\n')
                
                except Exception as e:
                    print(f"å¤„ç†æ ·æœ¬æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # æ‰“å°epochçš„å¹³å‡æŸå¤±
            avg_loss = total_loss / len(training_data)
            print(f"\nEpoch {epoch+1} å¹³å‡æŸå¤±: {avg_loss:.4f}")
            
            # epochç»“æŸæ—¶çš„è¯„ä¼°
            epoch_eval_loss = evaluate_model(llm, validation_data)
            print(f"Epoch {epoch+1} éªŒè¯é›†æŸå¤±: {epoch_eval_loss:.4f}")
            
            if current_step > total_steps:
                break
    
    print(f"\nStyleSphereè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯é›†æŸå¤±: {best_eval_loss:.4f}")

if __name__ == "__main__":
    train_stylesphere()
