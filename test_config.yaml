model_name_or_path: "E:/R1/TheBloke/Llama-2-7B-Chat-GGUF"  # 使用本地GGUF模型
model_type: "LLaMA"
dataset: "custom"
dataset_dir: "data"

output_dir: "outputs/stylesphere-test"
logging_dir: "logs"

do_train: true
overwrite_cache: false
overwrite_output_dir: true

# 减小batch size和训练步数用于快速迭代
per_device_train_batch_size: 1
gradient_accumulation_steps: 2
learning_rate: 3e-4
max_steps: 10  # 减少步数用于快速测试
warmup_steps: 2
logging_steps: 1
save_steps: 5
save_total_limit: 2
use_cpu: true  # 使用CPU进行测试
bf16: true

# LoRA参数
lora_rank: 8
lora_alpha: 32
lora_dropout: 0.05
lora_target: "q_proj,v_proj"

# 序列长度
max_source_length: 256
max_target_length: 256
preprocessing_num_workers: 4

load_in_8bit: true
